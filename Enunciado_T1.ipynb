{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Y1tHj3DNqhX"
   },
   "source": [
    "<img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/Isotipo-Negro.gif\" title=\"Title text\" width=\"20%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "<h1 align='center'> INF-395/477 Redes Neuronales Artificiales I-2018 </h1>\n",
    "\n",
    "<H3 align='center'> Tarea 1 - Redes Neuronales y *Deep Learning* </H3>\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "**Temas**  \n",
    "\n",
    "* Entrenamiento de redes *Feed-Forward* vı́a GD y variantes (SGD, mini-*batches*), *momentum*, regularización y tasa de aprendizaje adaptiva.\n",
    "* Rol de capas ocultas y mayor profundidad (*Deep Learning*).\n",
    "* Diseño y entrenamiento de Redes Neuronales Convolucionales (CNNs).\n",
    "* Aplicaciones de las Redes Neuronales Convolucionales\n",
    "* Técnicas de regularización: *Dropout* y *Batch Normalization* \n",
    "\n",
    "** Formalidades **  \n",
    "* Equipos de trabajo de: 2-3 personas (*cada uno debe estar en condiciones de realizar una presentación y discutir sobre cada punto del trabajo realizado*)\n",
    "* Se debe preparar una presentación de 20 minutos. Presentador será elegido aleatoriamente.\n",
    "* Se debe preparar un (breve) Jupyter/IPython notebook que explique la actividad realizada y las conclusiones del trabajo\n",
    "* Fecha de entrega y discusión: 26 de Abril.\n",
    "* Formato de entrega: envı́o de link Github al correo electrónico del ayudante (*<francisco.mena.13@sansano.usm.cl>*) , incluyendo al profesor en copia (*<jnancu@inf.utfsm.cl>*). Por favor especificar el siguiente asunto: [Tarea1-INF395-I-2019]\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "\n",
    "#### Paquetes instalación\n",
    "\n",
    "Para poder trabajar en el curso se necesitará instalar librerías para Python, por lo que se recomienda instalarlas a través de anaconda (para Windows y sistemas Unix) en un entorno virtual, donde podrán elegir su versión de Python. Se instalarán librerías como sklearn, una librería simple y de facil acceso para data science, keras en su versión con GPU (para cálculo acelerado a través de la tarjeta gráfica), además de que ésta utiliza como backend TensorFlow o Theano, por lo que habrá que instalar alguno de éstos, además de las librerías básicas de computer science como *numpy, matplotlib, pandas,* además de claramente *jupyter*.\n",
    "\n",
    "* Descargar anacona\n",
    "* Luego de instalar Anaconda y tenerla en el path de su computador crear un entorno virtual:\n",
    "```\n",
    "conda create -n redesneuronales python=version\n",
    "```\n",
    "con version, la version de Python que desea utilizar. Si está en Windows, se recomienda Python 3 debido a dependencias con una de las librerías a utilizar.\n",
    "\n",
    "* Acceder al ambiente creado\n",
    "```\n",
    "source activate redesneuronales\n",
    "```\n",
    "\n",
    "* Instalar los paquetes a utilizar\n",
    "```\n",
    "conda install jupyter sklearn numpy pandas matplotlib keras-gpu tensorflow-gpu\n",
    "```\n",
    "O vía *pip*\n",
    "```\n",
    "pip install jupyter sklearn numpy pandas matplotlib tensorflow-gpu keras\n",
    "```\n",
    "\n",
    "*  Para salir del entorno\n",
    "```\n",
    "source deactivate redesneuronales\n",
    "```\n",
    "\n",
    "No olvide revisar las dependencias de las versiones de librerías, por ejemplo la de tensorflow-gpu: https://www.tensorflow.org/install/source#tested_source_configurations\n",
    "\n",
    "<hr style=\"height:2px;border:none\"/>\n",
    "La tarea se divide en secciones:\n",
    "\n",
    "[1.](#primero) Red Neuronal *Feed Forward* para Detectar Exoplanetas  \n",
    "[2.](#segundo) *Deep Networks*  \n",
    "[3.](#tercero) Redes Convolucionales en Imágenes  \n",
    "[4.](#cuarto) CNN *vs* RNN Prediciendo el Ozono Atmosférico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84-hf1CuNqhZ"
   },
   "source": [
    "#### <a id=\"primero\"></a>\n",
    "## 1. Red Neuronal *Feed Forward* para Detectar Exoplanetas\n",
    "---\n",
    "\n",
    "Las Redes Neuronales Artificiales (ANN) son un tipo de modelo de aprendizaje que, con el suficiente número de capas, debiera poder aproximar cualquier función. Hoy en día se han aplicado a numerosos problemas, ya que tienen la ventaja de ser bastante dinámicas en su construcción y poder ser entrenadas con unicamente *backpropagation*, obteniendo un buen desempeño. Los modelos de aprendizaje son aplicados a diferentes ámbitos en donde, en algunos casos, automatizan extensivos procesos manuales de expertos, como lo que veremos a continuación.\n",
    "\n",
    "<img src=\"https://www.cfa.harvard.edu/~avanderb/tutorial/HAT-P-3b.gif\" title=\"YOLO\" width=\"30%\"/>\n",
    "\n",
    "En esta sección trabajaremos con un dataset de astronomía, **Kepler KOI** [[1]](#refs), en el cual podrán experimentar con la detección de exoplanetas a través de *features* extraídas de las curvas de luz (tránsito de los planetas sobre su estrella madre) y metadatos de la observación (planeta, estrella y curvas de luz). Para más información sobre los metadatos visite el siguiente __[link](https://exoplanetarchive.ipac.caltech.edu/docs/API_kepcandidate_columns.html)__. La tarea es determinar si un posible candidato a exoplaneta (en base a una previa identificación/selección de eventos que sobrepasan un cierto *treshold*) corresponde efectivamente a un exoplaneta o no.\n",
    "\n",
    "---\n",
    "En primer lugar cargue todos los datos trabajados por [[2]](#refs), los cuales se encuentran adjuntados con el enunciado. Además separe en entrenamiento y pruebas.\n",
    "```python\n",
    "import pandas  as pd\n",
    "import numpy as np\n",
    "df_sets = pd.read_csv(\"./koi_sets_unb.csv\")\n",
    "mask_train = (df_sets[\"Set\"] == \"Train\").values\n",
    "mask_test = (df_sets[\"Set\"] == \"Test\").values\n",
    "df_labels = pd.read_csv(\"./koi_labels.csv\")\n",
    "df_X = pd.read_csv(\"./koi_light_curves_X.csv\")\n",
    "df_labels_train = df_labels[mask_train]\n",
    "df_labels_test = df_labels[mask_test]\n",
    "df_X_train = df_X[mask_train]\n",
    "df_X_test = df_X[mask_test]\n",
    "```\n",
    "\n",
    "A continuación cree las matrices que trabajará y servirán para entrenar su modelo neuronal, la etiqueta binaria (0 o 1) y la matriz numérica de entrada, imputando el estadístico de la mediana sobre los valores nulos.\n",
    "```python\n",
    "y_train = ((df_labels_train[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "y_test = ((df_labels_test[\"NExScI Disposition\"]==\"CONFIRMED\")*1).values\n",
    "df_X_train = df_X_train.reset_index(drop=True)\n",
    "df_X_test = df_X_test.reset_index(drop=True)\n",
    "df_X_train.fillna(df_X_train.median(), inplace=True)\n",
    "df_X_test.fillna(df_X_test.median(), inplace=True)\n",
    "X_train = df_X_train.values[:,1:]\n",
    "X_test = df_X_test.values[:,1:]\n",
    "```\n",
    "\n",
    "> a) Explore los datos trabajados, ya sea con estadísticos simples o con gráficos como histogramas y/o boxplots. Comente sobre el problema enfrentado, es decir, la tarea de transformar un vector $X$ en un valor categórico (0 o 1).\n",
    "```python\n",
    "columns_names = df_X_train.columns[1:]\n",
    "print(columns_names)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "df_X_train.describe()\n",
    "```\n",
    "\n",
    "> b) Escale los datos para ser trabajados por el modelo de aprendizaje, indique la importancia de éste paso. Además cree un conjunto de validación extrayendo un cierto porcentaje del conjunto de entrenamiento, por ejemplo el 20% manteniendo el desbalanceo de clases (*split* stratificado).\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = ...\n",
    "X_test_scaled =  scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "> c) Muestre en un gráfico la función objetivo (*cross entropy*) para el conjunto de entrenamiento y de validación *vs* número de *epochs* de entrenamiento, para una red *feedforward* de 3 capas, con 256 unidades ocultas y función de activación sigmoidal. Entrene la red usando gradiente descendente estocástico con tasa de aprendizaje (*learning rate*) 0.01 y 100 *epochs* de entrenamiento. Comente. Si observa divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento. Compare el efecto de variar la función de activación a **ReLU** ¿Qué observa en la convergencia del modelo?\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"sigmoid\")) #this should be mantained\n",
    "model.compile(optimizer=SGD(lr=0.01),loss='binary_crossentropy')\n",
    "hist = model.fit(X_train_scaled, y_train, epochs=100, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "> Finalmente compare a través de una métrica de desempeño sobre el conjunto de pruebas, en este caso como trabajamos un problema desbalanceado, mida *f1 score weighted*, comente sobre esta decisión ¿Es esperable la diferencia entre relu y sigmoidal en base a los gráficos realizados?\n",
    "```python\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,model_sigmoid.predict_classes(X_test_scaled),average='weighted')\n",
    "f1_score(y_test,model_relu.predict_classes(X_test_scaled),average='weighted')\n",
    "```\n",
    "\n",
    "> d) Repita c) variando la tasa de aprendizaje (*learning rate*) en un rango sensible. Comente. Si observa divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento o para alguna de las dos funciones de activación experimentadas.\n",
    "```python\n",
    "import numpy as np\n",
    "n_lr = 20\n",
    "lear_rate = np.linspace(0,1,n_lr)\n",
    "```\n",
    "\n",
    "> e) Entrene los modelos considerados en c) usando *progressive decay*. Compare y comente.\n",
    "```python\n",
    "n_decay = 10\n",
    "lear_decay = np.logspace(-6,0,n_decay)\n",
    "sgd = SGD(lr=0.2, decay=1e-6)\n",
    "```\n",
    "\n",
    "> f) Entrene los modelos considerados en c) usando *momentum* [[3]](#refs). Experimente usando *momentum* clásico y *momentum* de Nesterov. ¿Observa un mejor resultado final? ¿Observa una mayor velocidad de convergencia sobre el conjunto de entrenamiento? ¿Sobre el conjunto de validación?\n",
    "```python\n",
    "split_space = 21\n",
    "momentum = np.linspace(0,1,split_space)\n",
    "sgd = SGD(lr=0.01,momentum=0.9,nesterov=False)\n",
    "```\n",
    "\n",
    "> g) Vuelva a entrenar los modelos considerados en c) utilizando SGD en mini-*batches*. Experimente con diferentes tamaños del *batch*. Comente sobre eficacia de convergencia (converge en menor número de *epochs*) *vs* eficiencia computacional (tiempo en converger o por *epoch*).\n",
    "```python\n",
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model.fit(X_train_scaled,y_train,batch_size=50,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "\n",
    "> h) Entrene los modelos obtenidos en c) utilizando estrategias modernas para adaptar la tasa de aprendizaje. Compare los desempeños de *adagrad, adadelta, RMSprop* y *adam*, ofrecidos en __[keras optimizer](https://keras.io/optimizers/)__. ¿Se observa en algún caso un mejor resultado final? ¿Se observa en algún caso una mayor velocidad de convergencia sobre el dataset de entrenamiento? ¿Sobre el dataset de validación?\n",
    "```python\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "model.compile(optimizer=moptimizer)\n",
    "model.fit(X_train_scaled,y_train,batch_size=bs,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "```\n",
    "\n",
    "> i) Entrene los modelos obtenidos en c) utilizando regularizadores clásicos $l_1$ y $l_2$ (*weight decay*). Compare los desempeños de prueba obtenidos antes y después de regularizar. Experimente con distintos valores del parámetro de regularización y comente. Además evalúe el efecto de regularizar solo la primera capa *vs* la segunda, comente. *Recuerde que la regularización se debe añadir a cada capa separadamente* ¿Dónde le parece más importante aplicar?\n",
    "```python\n",
    "from keras.layers import Activation\n",
    "from keras.regularizers import l1,l2\n",
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim=X_train_scaled.shape[1],kernel_initializer='uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('sigmoid')) #and relu\n",
    "model.add(Dense(1, kernel_initializer='uniform',kernel_regularizer=l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "```\n",
    "\n",
    "> j) Elija uno de los dos modelos definidos en c) y experimente con modificar la función objetivo, que hasta ahora se lo hemos dejado a keras definir la típica *binary cross entropy*, en pos de algún objetivo que decida plantearse, por ejemplo aumentar la velocidad de convergencia (reducir más rápida la función objetivo), obtener mejor desempeño en *f1 score* u algún otro.  \n",
    "*Se dejan algunos ejemplos*\n",
    "1. Focal loss [[4]](#refs)\n",
    "2. Cross entropy + Min entropy\n",
    "3. Cross entropy + Max entropy\n",
    "4. Kullback Leibler (KL) ó Jensen Shannon (JS) divergence [[5]](#refs)  \n",
    "5. Weighted Cross entropy  \n",
    "```python\n",
    "from keras import backend as K\n",
    "def custom_loss(value): #ejemplo\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = K.clip(y_true, K.epsilon(), 1) \n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1)\n",
    "        return K.sum(y_true * K.log(y_true / y_pred), axis=-1) #KL-divergence\n",
    "        ...#return value*K.mean(K.square(y_pred - y_true), axis=-1) #MSE\n",
    "    return loss\n",
    "model.compile(loss=custom_loss(1),optimizer=opt) #example of use\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFtCUBp9Nqhb"
   },
   "source": [
    "<a id=\"segundo\"></a>\n",
    "\n",
    "## 2. Deep Networks\n",
    "---\n",
    "Las *deep network*, o lo que hoy en día se conoce como *deep learning*, hace referencia a modelos de redes neuronales estructurados con muchas capas, es decir, el cómputo de la función final es la composición una gran cantidad de funciones ( $f^{(n)} = f^{(n-1)} \\circ f^{(n-2)} \\circ \\cdots \\circ f^{(2)} \\circ f^{(1)} $ con $n \\gg 0$ ).  \n",
    "Este tipo de redes neuronales tiene una gran cantidad de parámetros, creciendo exponencialmente por capa con las redes *feed forward*, siendo bastante difíciles de entrenar comparadas con una red poco profunda, esto es debido a que requieren una gran cantidad de datos para ajustar correctamente todos esos parámetros. Pero entonces ¿Cuál es el beneficio que tienen este tipo de redes? ¿Qué ganancias trae el añadir capas a una arquitectura de una red neuronal?   Y luego, lo más importante ¿Cómo entrenamos este tipo de redes?\n",
    "\n",
    "<img src=\"http://neuralnetworksanddeeplearning.com/images/tikz36.png\" title=\"Title text\" width=\"80%\" height=\"20%\" />\n",
    "\n",
    "\n",
    "\n",
    "En esta sección se estudiará la complejidad de entrenar redes neuronales profundas, mediante la visualización de los gradientes de los pesos en cada capa, el cómo varía mientras se hace el *backpropagation* hacia las primeras capas de la red. Además del efecto del cambio de funciones de activación.\n",
    "\n",
    "---\n",
    "\n",
    "Volveremos a trabajar con el dataset de exoplanetas de la [sección 1](#primero). Cárguelo y genere las matrices a trabajar.\n",
    "\n",
    "> a) En esta primera instancia se trabajará con una red *shallow* (poco profunda) con una gran cantidad de neuronas situadas en una capa, inicializada con pesos uniforme. Visualice el gradiente de la función de pérdida (*loss*) para el conjunto de entrenamiento (promedio del gradiente de cada dato) respecto a los pesos en las distintas capas, para esto se le pedirá el cálculo del gradiente para una capa mediante la función de *gradients* (__[link](https://www.tensorflow.org/api_docs/python/tf/keras/backend/gradients)__) en el *backend* de Keras, otra opción es a través de un __[monitor](https://keras.io/callbacks/#tensorboard)__. Deberá generar un **histograma** para todos los pesos de cada capa antes y despues del entrenamiento con 50 *epochs*. Comente.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(1280, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid'))\n",
    "compilar\n",
    "- ###calculate gradients\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "loss = keras.losses.mean_squared_error(model.output,y_train_scaled)\n",
    "listOfVariableTensors = model.trainable_weights \n",
    "gradients = K.gradients(loss, listOfVariableTensors) #We can now calculate the gradients.\n",
    "sess = K.get_session()\n",
    "evaluated_gradients = sess.run(gradients,feed_dict={model.input:X_train_scaled.values})\n",
    "evaluated_gradients = [gradient/len(y_train) for gradient in evaluated_gradients]\n",
    "```\n",
    "\n",
    "> b) Vuelva a generar los histogramas para los gradientes de los pesos de cada capa antes y después del entrenamiento pero ahora entrenando una red con los mimos pesos distribuidos a través de muchas más capas (red profunda de 6 capas), 5 capas escondidas y 1 de salida. Utilice el inicializador de pesos *uniform* el cual inicializa mediante una distribución uniforme entre $-1/\\sqrt{N}$ y $1/\\sqrt{N}$ para cada capa, con $N$ el número de neuronas de la capa anterior. Por simplicidad visualice las 3-4 primeras capas de la red. Comente si observa el efecto del *gradiente desvaneciente* antes y/o después de entrenar. ¿Qué sucede con la *loss*? ¿El modelo logra aprender?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='uniform',activation='sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01)\n",
    "compilar\n",
    "```\n",
    "\n",
    "> c) Vuelva a generar los histogramas para los gradientes de los pesos de cada capa antes y después del entrenamiento, pero ahora entrenando la red profunda con el inicializador de Glorot [[6]](#refs), es decir, una distribución uniforme entre -$\\sqrt{6/(N_{in}+N_{out})}$  y $\\sqrt{6/(N_{in}+N_{out})}$ . Por simplicidad visualice las 3-4 primeras capas de la red. Comente si el efecto del *gradiente desvaneciente* se amortigua antes y/o después de entrenar. ¿Qué sucede ahora con la *loss*? ¿El modelo logra aprender?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(256, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "sgd = SGD(lr=0.01)\n",
    "compilar\n",
    "```\n",
    "\n",
    "> d) Vuelva a repetir la experimentación ahora cambiando la función de activación por ReLU, es decir, deberá visualizar los gradientes de los pesos de cada capa antes y después del entrenamiento, con inicialización *uniform*, y comparar con la inicialización de He [[7]](#refs), es decir, una distribución uniforme entre -$\\sqrt{6/N_{in}}$ y $\\sqrt{6/N_{in}} $. Comente si ocurre el mismo fenómeno anterior (para función sigmoidal) sobre el efecto del *gradiente desvaneciente* para la función ReLU. Explique la importancia de la inicialización de los pesos dependiendo de la arquitectura. \n",
    "```python\n",
    "...\n",
    "model.add(Dense(nh, kernel_initializer='uniform',activation='relu')) #uniform\n",
    "...\n",
    "or\n",
    "...\n",
    "model.add(Dense(nh, kernel_initializer='he_uniform',activation='relu')) #he\n",
    "...\n",
    "```\n",
    "\n",
    "> e) Experimente con la utilización de una función activación auxiliar (debido a que aproxima) a '**ReLU**' y que es continua derivable (**softplus**) ¿Cuál es el beneficio de ésta con respecto ReLU? Comente.\n",
    "```python\n",
    "...\n",
    "model.add(Dense(nh, kernel_initializer='he_uniform',activation='softplus')) #softplus\n",
    "...\n",
    "```\n",
    "\n",
    "> f) ¿Qué es lo que sucede con la red más profunda? ¿El modelo logra convergencia en su entrenamiento? Vuelva a experimentar con variar las funciones de activación con el propósito de lograr un buen aprendizaje y generalización del modelo en base a la *loss*. Experimente con la familia ReLU (LeakyReLU, PReLU, ELU, ThresholdedReLU), algunas en el __[link](https://keras.io/layers/advanced-activations/)__. ¿Con cuál se aprende más rápido en términos de la *loss*? Además monitoree neuronas muertas (*dying neuron*) a través de los valores de la activación (por ejemplo ReLU con valor 0 no genera gradiente) con un histograma a lo largo del entrenamiento.  \n",
    "*Hint: ésto último se puede visualizar con lo de la pregunta b), __[TensorBoard](https://keras.io/callbacks/#tensorboard)__*.\n",
    "```python\n",
    "from keras.layers import LeakyReLU, PReLU, ELU, ThresholdedReLU\n",
    "LeakyReLU(alpha=0.3)\n",
    "PReLU(alpha_initializer='zeros')\n",
    "ELU(alpha=1.0)\n",
    "ThresholdedReLU(theta=1.0)\n",
    "...\n",
    "model.add(Dense(nh, activation='linear'))\n",
    "model.add(LeakyReLU(alpha=0.3))\n",
    "...\n",
    "```\n",
    "¿Las funciones de activaciones de cada capa necesariamente deben ser iguales? Comente sobre su respuesta.\n",
    "\n",
    "> g) Ahora, sin variar la profundidad de la red definida en b), se pedirá que experimente con otra variación que podría resultar provechoso para la generalización y aprendizaje del modelo, la técnica de *Dropout* [[8]](#refs) y la técnica de *Batch Normalization*[[9]](#refs). Decida si colocarlas en todas las capas o en algunas. Comente sobre el efecto esperado y el observado.\n",
    "```python\n",
    "from keras.layers import Dropout, BatchNormalization\n",
    "...\n",
    "model.add(Dense(nh, activation=act, kernel_initializer=init))\n",
    "model.add(Dropout(dropout_rate))\n",
    "...\n",
    "...\n",
    "model.add(Dense(nh, activation=act, kernel_initializer=init))\n",
    "model.add(BatchNormalization())\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tercero\"></a>\n",
    "## 3. Redes Convolucionales en Imágenes\n",
    "---\n",
    "\n",
    "En esta sección trabajaremos con un *dataset* bastante conocido y utilizado por la comunidad para experimentar reconocimiento de objetos en imágenes: CIFAR-10. Se trata de un conjunto de 60000 imágenes RGB de 32 × 32 pixeles que contiene 10 clases de objetos y 6000 ejemplos por clase. La versión utilizada se le atribuye a *A. Krizhevsky, V. Nair* y *G. Hinton*  [[10]](#refs), viene separada en 50000 ejemplos de entrenamiento y 10000 casos de prueba que fueron obtenidos seleccionando 1000 imágenes aleatorias de cada clase. Cabe destacar que las clases son mutuamente excluyentes y corresponden a las siguientes categorı́as: \n",
    "\n",
    "<img src=\"https://cv-tricks.com/wp-content/uploads/2017/03/alexnet_small.png.pagespeed.ce.j1fiN1R4Hv.png\" title=\"YOLO\" width=\"70%\" style=\"float: left;\"/>\n",
    "\n",
    "* Avión\n",
    "* Automóvil\n",
    "* Pájaro\n",
    "* Gato\n",
    "* Ciervo\n",
    "* Perro\n",
    "* Rana\n",
    "* Caballo\n",
    "* Barco\n",
    "* Camión\n",
    "\n",
    "\n",
    "Para esta tarea se experimentará con redes convolucionales, conocidas como CNNs ó ConvNets.  \n",
    "**Nota:** Para esta actividad es bastante aconsejable entrenar las redes usando una GPU, ya que de otro modo los tiempos de entrenamiento serán largos. \n",
    "\n",
    "\n",
    "**Recuerde que si encuentra cosas ventajosas en alguna pregunta, puede y debería seguir utilizandolas en las siguientes**\n",
    "\n",
    "---\n",
    "\n",
    "Cargue todos los datos de entrenamiento y pruebas del problema CIFAR. Además de generar un conjunto de validación del conjunto de entrenamiento y que no debe superar las 5000 imágenes.\n",
    "```python\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']  \n",
    "import numpy as np   \n",
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "... #create validation\n",
    "```\n",
    "\n",
    "> a) Visualice los datos que trabajaremos e intentaremos detectar en esta sección. ¿Qué dimensiones tienen las imágenes trabajadas? ¿Existen patrones similares entre los objetos de una misma clase? ¿Entre objetos de distintas clases?.\n",
    "```python\n",
    "idx_dato = [np.random.choice(np.where(y_train==i)[0]) for i in range(10)] #sample from each class\n",
    "f,axx = plt.subplots(2,5,figsize=(10,5))\n",
    "for i, dato in enumerate(idx_dato):\n",
    "    axx[int(i/5),i%5].imshow(x_train[dato])\n",
    "    axx[int(i/5),i%5].axis('off')\n",
    "    axx[int(i/5),i%5].set_title(label_names[i])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "> b) Prepare los subconjuntos de entrenamiento, validación y pruebas para ser entregados al modelo. Para ésto divida la intensidad original de pixel en cada canal por 255. Es importante notar que si desea trabajar con el orden de las dimensiones denominado ’th’ (por defecto para *Theano*) deberá realizar la transposición correspondiente para dejar el canal en donde corresponda. Finalmente, genere una representación adecuada de las salidas deseadas de la red.\n",
    "```python\n",
    "import keras\n",
    "..#x_train = x_train.transpose([0, 3, 1, 2]) #if 'th' dim-ordering is used\n",
    "..#x_test= x_test.transpose([0, 3, 1, 2]) \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "Xnorm_train = x_train.astype('float32')/255\n",
    "Xnorm_val = x_val.astype('float32')/255\n",
    "Xnorm_test = x_test.astype('float32')/255\n",
    "```\n",
    "\n",
    "> c) Defina una CNN simple con arquitectura $C \\times P \\times C \\times P \\times F \\times F$. Para ambas capas convolucionales utilice 32 y 64 filtros de $3 \\times 3$ y funciones de activación ReLU respectivamente. Para las capas de *pooling* utilice filtros de $2 \\times 2$ con *stride* 2. Para la capa MLP escondida use 512 neuronas. Genere un esquema lo más compacto posible que muestre los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un *forward-pass* y el número de parámetros de cada capa.\n",
    "```python\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=Xnorm_train.shape[1:],activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()\n",
    "```\n",
    "\n",
    "> d) Entrene la CNN definida en **c)** utilizando SGD. En este dataset, una tasa de aprendizaje “segura” es $\\eta = 10^{-4}$ o inferior con una tasa de decaimiento, pero durante las primeras *epochs* el entrenamiento resulta demasiado lento. Para resolver el problema compare el entrenar con un optimizador adaptativo como es **RMSProp** con parámetros similares. Construya un gráfico que muestre los errores de entrenamiento, validación y pruebas como función del número de “epochs”, entrene con 25 *epochs*.\n",
    "```python\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = SGD(lr=1e-4,decay=1e-6)\n",
    "model.compile( ... )\n",
    "model.fit(Xnorm_train, y_train,batch_size=batch_size,epochs=epochs, validation_data=(Xnorm_val,y_val))\n",
    "opt = rmsprop(lr=1e-4, decay=1e-6)\n",
    "model.compile( ... )\n",
    "model.fit(Xnorm_train, y_train,batch_size=batch_size,epochs=epochs, validation_data=(Xnorm_val, y_val))\n",
    "```\n",
    "\n",
    "> e) Ahora bien, para mejorar los resultados encontrados deberá aumentar o reducir el número de capas, dependiendo de qué dice su intuición. Deberá elegir sobre dónde aumentar o reducir el número de capas, la fase convolucional y/o la fase *feed forward*, no olvide que al aumentar el número de capas (como en la sección 2) conlleva ciertas consecuencias, lo más importante el *overfitting*, vea cómo reducir ésto.\n",
    "\n",
    "\n",
    "> f) Duplique el tamaño de los filtros utilizados en la primera capa convolucional. ¿Qué efecto tiene esto sobre el tipo de patrones que detectará la red? ¿Porqué usar filtros pequeños no impide detectar patrones más grandes?\n",
    "```python\n",
    "...\n",
    "model.add(Conv2D(nf*2,(nc, nc),padding='same',input_shape=Xnorm_train.shape[1:],activation='relu'))\n",
    "...\n",
    "```\n",
    "\n",
    "> g) Duplique el número de filtros utilizados en las capas convolucionales. ¿Qué efecto tiene esto sobre la capacidad de aprendizaje de la red?\n",
    "```python\n",
    "...\n",
    "model.add(Conv2D(nf,(nc*2, nc*2),padding='same',input_shape=Xnorm_train.shape[1:],activation='relu'))\n",
    "...\n",
    "```\n",
    "\n",
    "> h) Se ha sugerido que la práctica bastante habitual de continuar una capa convolucional con una capa de *pooling* puede generar una reducción prematura de las dimensiones del patrón de entrada. Experimente con una arquitectura del tipo $C \\times P \\times C \\times P \\times F \\times F$ versus  $C \\times C \\times P \\times C \\times C \\times P \\times F \\times F$. Use 32 filtros para la primera capa convolucional y 64 para la segunda.  Como resultado final de esta actividad, al igual que las otras, grafique los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "> **Hint:** con esta nueva arquitectura debiese superar el 70% de accuracy (de validación/test), pero la arquitectura es más sensible a overfitting por lo que podrı́a ser conveniente agregar un regularizador ¿Dónde? ¿Qué tan potente?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=Xnorm_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "dropout?\n",
    "...\n",
    "```\n",
    "\n",
    "> i) Algunos investigadores, han propuesto que las capas de *pooling* se pueden reemplazar por capas convoluciones con *stride* 2. ¿Se reduce dimensionalidad de este modo? Compruébelo verificando los cambios de forma (dimensionalidad) que experimenta un patrón de entrada a medida que se ejecuta un *forward-pass*. Entrene la red resultante con el método que prefiera, gráficando los errores de entrenamiento, validación y pruebas como función del número de “epochs” (fijando el máximo en un número razonable como T = 25).\n",
    "```python\n",
    "...\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), strides=(2, 2), padding='same',activation='linear'))\n",
    "...\n",
    "```\n",
    "\n",
    "> j) Una forma interesante de regularizar modelos entrenados para visión artificial consiste en “aumentar” el número de ejemplos de entrenamiento usando transformaciones sencillas como: rotaciones, corrimientos y reflexiones, tanto horizontales como verticales. Explique por qué este procedimiento podrı́a ayudar a mejorar el modelo y el por qué las etiquetas no cambian al aplicar estas operaciones. Evalúe experimentalmente la conveniencia de incorporarlo.\n",
    "```python\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of height)\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "datagen.fit(Xnorm_train)\n",
    "model.fit_generator(datagen.flow(Xnorm_train, y_train,batch_size=batch_size),steps_per_epoch=Xnorm_train.shape[0]// batch_size, epochs=epochs,validation_data=(Xnorm_val, y_val))\n",
    "```\n",
    "\n",
    "> k) Ahora se experimentará con el concepto de *transfer learning* [[11]](#refs), el cual consta en transferir conocimiento de un dominio fuente (*source domain*) a un dominio objetivo (*target domain*). En redes neuronales existen muchas representaciones de esto, en común consta en pre inicializar los pesos de la red de alguna manera que no sea con distribuciones de manera aleatoria, conocido como *fine tunning*. También está lo que es utilizar una representación generada a través de otra red entrenada con muchos datos, esto es tomar la red y \"congelar\" sus primeras capas para tomar esta representación y no entrenar esos pesos. Para ésto se utilizará VGG16 [[12]](#refs), una red entrenada con millones de imágenes y proporcionada a través de la interfaz de *keras*. Visualice el modelo y sus 23 capas.  Para esta instancia se utilizará todo lo aprendido por las capas convolucionales, es decir, se eliminan las capas densas del modelo y se agregan unas nuevas a ser entrenadas desde cero.  \n",
    "*Recuerde normalizar los datos de la manera en que fue entrenado VGG* ¿Cuál es éste proceso?\n",
    "```python\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X_train_vgg = preprocess_input(x_train.astype('float32'))\n",
    "X_test_vgg = preprocess_input(x_test.astype('float32'))\n",
    "input_tensor=Input(shape=X_train_vgg.shape[1:])\n",
    "modelVGG = VGG16(weights='imagenet', include_top=False,input_tensor=input_tensor ) # LOAD PRETRAINED MODEL \n",
    "features_train = modelVGG.predict(X_train_vgg)\n",
    "features_test = modelVGG.predict(X_test_vgg)\n",
    "modelVGG.summary()\n",
    "```\n",
    "\n",
    "> l) Entrene esta red agregando una capa densa de 512 neuronas seguido de un dropout de 0.5, finalmente es necesario agregar la capa de clasificación para las 10 clases. Utilice la misma configuración del optimizador para que las comparaciones sean válidas. Entrene unicamente por 15 *epochs* y grafique las curvas de entrenamiento con respecto al modelo definido en c) y la mejor encontrada ¿Qué sucede? Comente.\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "...#clasification\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> m) Agregue una capa de normalización (*Batch Normalization* [[9]](#refs)) de las activaciones en las capas densas, esto es, restar por la media del *mini-batch* y dividir por la desviación estándar en conjunto con unos parámetros aprendibles, además de agregar *Dropout*[[8]](#refs). Vuelva a entrenar el modelo con la misma configuración. Comente lo observado y compare las curvas de convergencia con los modelos anteriores ¿Por qué esto mejora a lo presentado en l)? ¿Qué beneficio tiene resolver un problema con una red pre-entrenada?\n",
    "```python\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=features_train.shape[1:]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(value))\n",
    "...#clasification\n",
    "model.compile(optimizer=optimizer_,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(features_train, y_train,epochs=epochs_, batch_size=128,verbose=1,validation_data=(features_test,y_test))\n",
    "```\n",
    "\n",
    "> n) Genere $T$ nuevas etiquetas para el dataset de CIFAR en base a las etiquetas de éstas, pero que sean \"paralelas\", es decir, un objeto/imagen puede tener una etiqueta de las posibles en CIFAR y una de las nuevas que usted genere, ésto se denomina **Multi-task**[[13]](#refs). Por ejemplo una nueva *task* podría ser identificar/distinguir entre animales u objetos (de manera binaria, 0 y 1) en los datos de CIFAR, ésto debe ser unicamente extraído a través de las etiquetas de CIFAR. Defina la sección compartida de la red, que se compartirá para aprender las $T+1$ tareas, que tome como entrada las imágenes de CIFAR, ya sean los pixeles o la representación de *VGG* y genere como salida una representación intermedia (*hidden*) que servirá después para aprender la probabilidad (*softmax* o *sigmoid*) de cada *task*.\n",
    "```python\n",
    "...# create your new tasks\n",
    "shared_model = Sequential()\n",
    "...\n",
    "shared_model.add(Dense(n_hidd,activation='relu'))\n",
    "shared_model.summary() \n",
    "```\n",
    "\n",
    "> o) Defina y entrene el modelo multi-task que prediga las $T$ nuevas *task* que definió en la pregunta anterior más la clasificación sobre CIFAR, *task 1*. Grafique las $T+1$ funciones objetivos que se optimizan en paralelo, comente. Verifique si el uso de las nuevas $T$ *task* auxiliares ayudan a regularizar a la red sobre la tarea principal, la clasificación sobre las etiquetas de CIFAR (*task 1*).   \n",
    "*Como ayuda se entrega que como la task1 es la clasificación de CIFAR la loss1 debiera ser 'categorical crossentropy'*\n",
    "```python\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "input_tasks = Input(shape = X.shape[1:])\n",
    "shared = shared_model(input_tasks) #shared_part\n",
    "class_cifar = Dense(10,activation='softmax')(shared)\n",
    "task2 = Dense(??)(shared)\n",
    "task3 = Dense(??)(shared)\n",
    "...\n",
    "multitask_model = Model(inputs=input_tasks, outputs = [class_cifar, task2, task3, ...])\n",
    "multitask_model.compile(loss = [loss1,loss2,loss3,...],optimizer=optimizer_, metrics=[\"acc\"])\n",
    "multitask_model.fit(X, [Y_cifar,Y_task2,Y_task3,...],epochs=25,batch_size=BATCH_SIZE,verbose=1)\n",
    "```\n",
    "\n",
    "> Una forma cómoda de visualizar el modelo es a través de *plot model* de *keras*.\n",
    "```python\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot,plot_model\n",
    "SVG(model_to_dot(multitask_model).create(prog='dot', format='svg'))\n",
    "```\n",
    "\n",
    "> p) Elija una de las redes entrenadas en esta sección (preferentemente una con buen desempeño) y determine las predicciones menos insegura de la red, en base a algún criterio (por ejemplo la predicciones con mayor entropía en su probabilidad), también ver en qué etiquetas se tiende a confundir, por ejemplo la red podría a tender a confundir camiones con autos. Conjeture el motivo de tal confusión. *Para esto último se puede generar una __[matriz de confusión](https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html)__*\n",
    "\n",
    "> q) Elija una de las redes entrenadas (preferentemente una con buen desempeño) y visualice los pesos correspondientes a los filtros de la primera capa convolucional. Visualice además el efecto del filtro sobre algunas imágenes de entrenamiento (*forward pass*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cuarto\"></a>\n",
    "## 4. CNN *vs* RNN Prediciendo el Ozono Atmosférico\n",
    "---\n",
    "\n",
    "En esta actividad utilizaremos redes neuronales para predicción de series de tiempo. Dada una serie de registros del valor de una variable en el tiempo (serie de tiempo) nos interesa entrenar un modelo que pueda predecir los valores futuros de la misma serie. \n",
    "\n",
    "En este caso, la serie corresponde a las concentraciones diarias (máximas) de $O_3$ medidas en la comuna de Las Condes entre Diciembre de 2003 y Diciembre de 2016. El $O_3$ (a nivel respirable) es un contaminante con graves efectos sobre la salud humana y sobre la agricultura, por lo que monitorear y predecir sus concentraciones en el tiempo es de gran relevancia. Se sabe que el $0_3$ alcanza sus niveles máximos en verano, por lo que estudiaremos sólo esos períodos. Esto hace que la serie que usted recibirá no es totalmente continua en el tiempo en el sentido de que los registros se miden hasta marzo de un año y se reinician en noviembre de ese mismo año. **Por favor considere atentamente esta situación.**   \n",
    "\n",
    "El archivo *CSV* que usted recibirá tiene las siguientes columnas \n",
    "\n",
    "[‘registered_on’, ‘CO', 'PM10', 'PM25', 'NO', 'NOX', 'WD', 'RH', 'TEMP', 'WS', 'UVA', 'UVB', 'O3']\n",
    "\n",
    "El primero corresponde a la fecha del registro. La última columna corresponde a la variable que queremos predecir y las demás son mediciones de otros contaminantes y de variables meteorológicas que podrían ayudar a predecir los niveles de $O_3$.  \n",
    "\n",
    "Su tarea consistirá en entrenar una red capaz de predecir los niveles de ozono el día de mañana sólo partir de los niveles *previas* de ozono y demás variables. Para ésto pre-procesaremos los datos, cada contaminante tendrá su serie de tiempo y asociada con las otras. Con ésto deberemos generar *secuencias de entrenamiento*, recordar que cada secuencia estará asocaida a un *Target* que es el $O_3$ del día siguiente.\n",
    "\n",
    "Compararemos y aplicaremos redes convolucionales uni-dimensionales y redes neuronales recurrentes, las cuales se adaptan perfectamente a escenarios de secuencias ya que modelan que el estado actual se genera a partir del estado anterior (como en una cadena de Markov).\n",
    "\n",
    "---\n",
    "\n",
    "En primer lugar carge el *csv* en un dataframe de pandas \n",
    "\n",
    "> a) Explore los datos y visualícelos, ya sea a través de medidas de tendencia o gráficos. Lo primero que deberá realizar será crear su conjunto de validación/test a partir de los datos, por ejemplo las últimas mediciones puesto que la tarea será predecir los datos futuros (*out of box*). Además escale los datos apropiadamente.\n",
    "\n",
    "#### Solo con input: Ozono (1-D)\n",
    "Considere para construir las secuencias de entrenamiento sólo la información previa del $O_3$\n",
    "\n",
    "> b) Ahora nos gustarı́a manipular los datos, para que hagamos la predicción para el tiempo siguiente usando los valores de los últimos perı́odos de tiempo. El número de perı́odos de tiempos \"hacia atrás\" que usaremos se denomina *lag*. Por ejemplo, tendremos un *lag* igual a 3, si para predecir el valor $x_{t+1}$ en el tiempo siguiente usamos la información del tiempo actual $x_t$ y la de los dos perı́odos anteriores $x_{t-1}$ y $x_{t-2}$ como variables de entrada. Realice una función que reciba una secuencia de valores y la transforme en dos arreglos *dataX* (inputs) y *dataY* (targets), además utilicela para generar los conjuntos de entrenamiento y test para el problema decidiendo el valor del *lag*.\n",
    "```python\n",
    "def create_dataset(dataset,lag=1):\n",
    "    return np.array(dataX),np.array(dataY)\n",
    "```\n",
    "Por ejemplo si en el dataset tenemos el arreglo 20.7,17.9,18.8,14.6,15.8,15.8,10.1.\n",
    "```python\n",
    "create_dataset(dataset,3)\n",
    "```\n",
    "La función debiese generar $(X_1,X_2,X_3)$ e $Y$:\n",
    "\n",
    "\n",
    "|$X_0$|$X_1$|$X_2$|Y|\n",
    "|---|---|---|---|\n",
    "|20.7|17.9|18.8|14.6|\n",
    "|17.9|18.8|14.6|15.8|\n",
    "|18.8|14.6|15.8|15.8|\n",
    "|14.6|15.8|15.8|10.1|\n",
    "\n",
    "\n",
    "```python\n",
    "lag = #your call\n",
    "trainX, trainY = create_dataset(stream_train_scaled, lag)\n",
    "testX, testY = create_dataset(stream_test_scaled, lag)\n",
    "```\n",
    "\n",
    "> c) En estos momentos tenemos nuestros datos en la forma [*samples, features*]. Sin embargo, la red RNN necesita que los datos se encuentren en un arreglo de tres dimensiones [*samples, time steps, features*]. Transforme el  conjuntos de entrenamiento y de pruebas a la estructura deseada, incorporando el *lag* como *features*. Defina dos modelos para comparar, una red recurrente simple y una red convolucional unidimensional (donde el kernel es un vector de largo $w$), comente sobre las dimensiones/*shape* de los parámetros de cada una de las redes. Entrene los dos modelos con la nueva representación ¿Qué limitaciones tiene el tamaño/*width* del kernel de la convolucional?.\n",
    "```python\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,SimpleRNN\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(units=4, input_shape=(1,lag), activation='tanh',return_sequences=False,go_backwards=False))\n",
    "model_rnn.add(Dense(1,activation='linear'))\n",
    "model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_rnn.summary()\n",
    "rnn_weights = model_rnn.get_weights()\n",
    "model_rnn.fit(trainX, trainY, epochs=25, batch_size=1, verbose=1)\n",
    "...#and now CNN\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(4, kernel_size=?,input_shape=(1,lag), activation='relu',padding='valid')) \n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(1,activation='linear'))\n",
    "model_cnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_cnn.summary()\n",
    "cnn_weights = model_cnn.get_weights()\n",
    "model_cnn.fit(trainX, trainY, epochs=25, batch_size=1, verbose=1)\n",
    "```\n",
    "\n",
    "> d) Mida desempeño de los dos modelos a través del *root mean square error* (RMSE) y compare. Para ésto deberá realizar las predicciones sobre el conjunto de entrenamiento y pruebas/validación, recuerde denormalizar los datos para que el error pueda ser computado en la escala original del rango de valores.\n",
    "```python\n",
    "trainPredict = model.predict(trainX,batch_size=batch_size)\n",
    "trainPredict = scaler.inverse_transform(trainP)\n",
    "trainY = scaler.inverse_transform([trainY])\n",
    "from sklearn.metrics import mean_squared_error\n",
    "...# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n",
    "```\n",
    "\n",
    "> e) Grafique las predicciones del conjunto de entrenamiento y pruebas/validación, y contrástelas con la serie de tiempo original. Muestre un extracto de la predicción para ver en mas detalle cómo es la predicción del modelo, comente.\n",
    "```python\n",
    "...# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(dataframe.values)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[lag:len(trainPredict)+lag, :] = trainPredict\n",
    "...# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(dataframe.values)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[(len(trainPredict)+2*lag):, :] = testPredic\n",
    "```\n",
    "\n",
    "\n",
    "> f) En lugar de aumentar el número de dimensiones como el el paso c), entrene la red con un *timestep=lag* y con dimensión de entrada = 1. Compare y comente sobre el cambio de dimensiones y número de parámetros de las redes ¿Cuál tipo de red tiene más parámetros y porqué? ¿Se produce una mejora del error de entrenamiento y pruebas? ¿Los tiempos de computación son comparables? Comente brevemente sobre cuál es la forma correcta para aprovechar la información a través del tiempo, si con esta forma o la realizada en el paso e).\n",
    "```python\n",
    "trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(SimpleRNN(units=4, input_shape=(lag,1), activation='tanh',return_sequences=False,go_backwards=False))\n",
    "model_rnn.add(Dense(1,activation='linear'))\n",
    "model_rnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model_rnn.fit(trainX, trainY, epochs=25, batch_size=1, verbose=1)\n",
    "model_rnn.summary()\n",
    "... #and now CNN\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv1D(4, kernel_size=3,input_shape=(lag,1), activation='relu',padding='valid')) # or kernel=2\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(1,activation='linear'))\n",
    "model_cnn.summary()\n",
    "```\n",
    "\n",
    "> g) Compare el desempeño de ambos modelos al variar el *lag* definido en c), recuerde que puede variarlo entre 1 y $T_{max}$. Comente brevemente sobre qué resulta mejor, el tener más información para predecir o si ésto satura la predicción por el efecto del gradiente desvaneciente ¿Ésto ocurre sólo con el modelo recurrente o con el convolucional también? ¿Por qué?\n",
    "\n",
    "> h) Como habrá notado, si usa una ventana de tiempo/*timesteps* muy larga ($T$ grande), las redes tienen dificultades para aprender. Para abordar este problema se le pide experimentar con la siguiente idea: dividir una secuencia de largo $T$ en trozos de largo $K$ y representarla como una matriz de $T/K$ columnas (asumamos que $T$ es un múltiplo de $K$) y $K$ filas, y entrenar la red para procesar la secuencia formada las columnas de esa matriz. De este modo, la red debe aprender dependencias temporales más cortas (largo $T/K$ en vez de $T$), pero accede a toda la información original en forma de atributos ($K$). Llamaremos a esta idea “**time folding**”. Se le recomienda usar un valor de $K$ que tenga sentido en el problema (por ejemplo $K=7$ representaría una semana). Defina y entrene los modelos para ésta nueva representación.  \n",
    "¿Cómo se ven afectados los modelos?\n",
    "```python\n",
    "model_rnn = ?\n",
    "model_cnn = ?\n",
    "```\n",
    "\n",
    "> i) [Opcional] Experimente con variar el número de unidades de la red recurrente (RNN) y el número de filtros de las capas convolucionales. Comente\n",
    "\n",
    "> j) [Opcional] Experimente con variar el *width* de los filtros convolucionales ¿Cuál sería el efecto de ésto? ¿Qué limite tiene (mayor y menor)?\n",
    "\n",
    "\n",
    "#### Agregar otras mediciones como input:  $CO, PM10, NO, NO_x,...,UVB, O_3$\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/scaled-ml-2018-180529212354/95/role-of-tensors-in-machine-learning-2-638.jpg?cb=1527629345\" title=\"tensors\" width=\"65%\"/>\n",
    "\n",
    "*Decida si continuar con la convolucional 1D o cambiar a convolucional 2D, comente sobre ésta decisión.*\n",
    "\n",
    "> k) Agregue las otras mediciones como nuevos valores de entrada al modelo definido en f), por lo que ahora se transforma la serie de tiempo a N-Dimensional, se tiene un *timestep=lag* con un *features*= mediciones nuevas + Ozono. Defina los nuevos modelos con el mejor *lag* encontrado en g).\n",
    "```python\n",
    "...#ejemplo:\n",
    "new_sequences = np.vstack([co_seq,pm10_seq,...,O3_seq]) # (Contaminantes, dias de verano entre 2003-2016)\n",
    "```\n",
    "\n",
    "\n",
    "> l) Entrene los modelos  ¿Se observan los mismos resultados? ¿Las mediciones incorporadas como información adicional ayudan al modelo? Comente y compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YAYlvfT-Nqhw"
   },
   "source": [
    "<a id=\"refs\"></a>\n",
    "## Referencias\n",
    "[1] Borucki, W. J., Koch, D. G., Basri, G., Batalha, N., Boss, A., Brown, T. M., ... & Dunham, E. W. (2011). *Characteristics of Kepler planetary candidates based on the first data set*. The Astrophysical Journal, 728(2), 117. also in: https://exoplanetarchive.ipac.caltech.edu/index.html  \n",
    "[2] Bugueno, M., Mena, F., & Araya, M. *Refining Exoplanet Detection Using Supervised Learning and Feature Engineering*.  \n",
    "[3] Sutskever, I., Martens, J., Dahl, G. E., & Hinton, G. E. (2013). *On the importance of initialization and momentum in deep learning*. ICML (3), 28(1139-1147), 5.  \n",
    "[4] Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P. (2017). *Focal loss for dense object detection*. In Proceedings of the IEEE international conference on computer vision (pp. 2980-2988).  \n",
    "[5] Chen, P., Chen, Y., & Rao, M. (2008). *Metrics defined by Bregman divergences: Part 2*. Communications in Mathematical Sciences, 6(4), 927-948.  \n",
    "[6] Glorot, X., & Bengio, Y. (2010, March). *Understanding the difficulty of training deep feedforward neural networks*. In Proceedings of the thirteenth international conference on artificial intelligence and statistics (pp. 249-256).   \n",
    "[7] He, K., Zhang, X., Ren, S., & Sun, J. (2015). *Delving deep into rectifiers: Surpassing human-level performance on imagenet classification*. In Proceedings of the IEEE international conference on computer vision (pp. 1026-1034).    \n",
    "[8] Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). *Dropout: a simple way to prevent neural networks from overfitting*. The Journal of Machine Learning Research, 15(1), 1929-1958.  \n",
    "[9] Ioffe, S., & Szegedy, C. (2015). Batch normalization: *Accelerating deep network training by reducing internal covariate shift*. arXiv preprint arXiv:1502.03167.  \n",
    "[10] Krizhevsky, A., Nair, V., & Hinton, G. (2014). *The CIFAR-10 dataset*. online: http://www.cs.toronto.edu/kriz/cifar.html , 4.  \n",
    "[11] Bengio, Y. (2012, June). *Deep learning of representations for unsupervised and transfer learning*. In Proceedings of ICML Workshop on Unsupervised and Transfer Learning (pp. 17-36).  \n",
    "[12] Simonyan, K., & Zisserman, A. (2014). *Very deep convolutional networks for large-scale image recognition*. arXiv preprint arXiv:1409.1556.  \n",
    "[13] Ruder, S. (2017). *An overview of multi-task learning in deep neural networks*. arXiv preprint arXiv:1706.05098.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Enunciado.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
